#+AUTHOR: Solomon Bothwell
#+TITLE: Polynomials For Fun and Profit

I've been working on projects related to [[https://topos.site/poly-book.pdf][Polynomial Functors]] recently
and I wanted to share a little bit of that work and why I find it so
exciting.

~Poly~ is the ~Category~ of polynomials where objects are polynomials
,which turn out to be a special class of ~Functors~, making morphisms
into ~Natural Transformations~ between those ~Functors~. It turns out
that this category has a tremendous amount of power.

We can use ~Poly~ describe algebraic data types, dependent lenses,
finite state machines, neural networks, user interfaces, game
interactions, wiring diagrams, and any kind of general dynamical
system.

~Poly~ also has seven tensor products which allow for a huge range of
compositional opportunities.

~Poly~ has inherent dependencies which require to encode it in a
dependently typed programming language. This admittedly limits the
direct applicability until suitable dependently typed languages become
more mainstream. Such work is certainely underway and in the mean time
we can explore incredible potential of ~Poly~ using a proof checker
such as Agda.

* Objects in ~Poly~

Our objects are literally the polynimals you may remember from gradeschool:

#+begin_src 
P(y) = y² + 2y + 1
#+end_src

In our categorification, we encode them as sums of ~Representable
Functors~. For an explanation (and application!) of ~Representable
Functors~, see my post on [[https://blog.cofree.coffee/2020-10-17-bounded-space-automata/][Bounded Space Automata]].

The one-liner explanation of ~Representable~ is that some ~Functor~
~f~ is said to be ~Representable~ by some type ~Rep f~ such that the
elements of ~Rep f~ completely index the elements of ~f~. In other
words we can write the following two isomorphic functions:

#+begin_src haskell
  tabulate :: (Rep f -> a) -> f a
  index :: f a -> Rep f -> a
#+end_src

The simplest example would be to say that ~Identity~ is ~Representable~ by ~()~:

#+begin_src haskell
  tabulate :: (() -> a) -> Identity a
  tabulate f = Identity (f ())
  index :: Identity a -> () -> a
  index (Identity a) () = a
#+end_src

With ~Fin~, the type of finite sets, we can say that an ~n~ sized
tuple is representable by ~Fin n~. For example:

#+begin_src agda
  tabulate : ∀{A : Set} → (Fin 2 → A) → (A × A)
  tabulate f = (f zero) , (f (suc zero))
  
  index : ∀{A : Set} → (A × A) → Fin 2 → A
  index (a , b) zero = a
  index (a , b) (suc z) = b
#+end_src

NOTE: This is the same as saying ~Vec n a~ is ~Representable~ by ~Fin
n~.

So how does this help us encode a polynomial?
First, we can do a little manipulation of `P` to simplify the coefficients:

#+begin_src 
  P(y) = y² + 2y + 1
  P(y) = y² + y¹ + y¹ + y⁰
#+end_src

Next we want to focus on those exponents.

The exponent ~aᵇ~ corresponds to a function ~b → a~. By applying that
knowledge to ~P~ we get:

```
P(y) = (2 → y) + (1 → y) + (1 → y) + (0 → y)
```

Lastly, lets interpret those naturals as finite sets:

```
P(x) = (Fin 2 → x) + (Fin 1 → x) + (Fin 1 → x) + (Fin 0 → x)
```

And voila! Each summand of ~P~ is a representable corresponding to a
tuple of of length equal to the exponent.

The polynomial ~P~ is thus a sum of representables.

We can then ~tabulate~ each of our ~Representables~ and to produce a sum of tuples:

#+begin_src 
P(y) = (y × y) + y + y + 1
data P y = One (y, y) | Two y | Three y | Four
#+end_src
NOTE: ~Two~ and ~Three~ are the one element tuple and ~Four~ is the zero element tuple.

Thus we can also use polynomials to describe algebraic datatypes.

Here are a couple more examples:

#+begin_src haskell
-- Identity(x) = x
-- Identity(x) = (Fin 1 -> x)
data Identity x = Identity x
#+end_src

#+begin_src haskell
-- Maybe(x) = x + 1
-- Maybe(x) = (Fin 1 → x) + 1
data Maybe x = Just x | Nothing
#+end_src

* Visualization as Corolla Forests
A helpful visualization tool is the so called Corolla Forest where we
draw a forest of trees. We draw one tree per summand the number of
branches corresponds to the size of the exponent.

Here is the Corolla Forest for our friend ~y² + 2y + 1~:

#+begin_src latex
\[
\begin{tikzpicture}[trees]
  \node[label={[yshift=-1.5em] \textbf{1}}] (1) {$\bullet$}
    child {}
    child {};
  \node[right=.5 of 1, label={[yshift=-1.5em] \textbf{2}}] (2) {$\bullet$} 
    child {};
  \node[right=.5 of 2, label={[yshift=-1.5em] \textbf{3}}] (3) {$\bullet$} 
    child {};
  \node[right=.5 of 3, label={[yshift=-1.5em] \textbf{4}}] (4) {$\bullet$};
\end{tikzpicture}
\]
#+end_src

* An encoding in Agda

Now that we have a basic intuition for Polynomials as sums of
~Representables~ we can move on to how we actually encode this in
Agda. This will reveal the inherently dependent nature of polynomials.

#+begin_src agda
record Poly : Set where
  constructor poly
  field
    Base : Set
    Fiber : Base → Set
#+end_src

~Base~ describes the number of summands and ~Fiber~ picks out the
~Representable~ for each summand.

Our friend ~y² + 2y + 1~ becomes:
#+begin_src agda
p : Poly
p .Base = Fin 4
p .Fiber  = λ where
  zero →  Fin 2
  (suc zero) → Fin 1
  (suc (suc zero)) →  Fin 1
  (suc (suc (suc zero))) → Fin 0
#+end_src

To interpret ~p~ into a ~Functor~, as we showed earlier, we use a Sigma
type:

#+begin_src agda
-- | Interpretation of a Poly as a functor @Set → Set@
⟦_⟧ : ∀ {a b} → Poly → (Set a → Set b)
⟦ P ⟧ X = Σ[ label ∈ P .Base ] (P .Fiber label → X)
#+end_src

The Sigma here says that for each label in ~P.Base~ we have a function
of type ~P.Fiber label → X~, where ~P.Fiber label~ represents the type
for the ~label~ summaand.

For example, the first summand of ~p~ is interpreted as ~Fin 2 → X~.

One interesting trick here is that if we define all of our functors
via ~Poly~ then we can define a parametrically polymorphic ~map~
operation for all functors:

#+begin_src agda
mapₚ : ∀{P : Poly} → ∀{A B : Set} → (A → B) → ⟦ P ⟧ A → ⟦ P ⟧ B
mapₚ f (tag , args) = tag , λ x → f (args x)
#+end_src

There is no need to define ad-hoc instances of ~fmap~ when using
~Poly~ to build your functors :)

* Morphisms in ~Poly~

Since objects in ~Poly~ are ~Functors~, morphisms in ~Poly~ must be
~Natural Transformations~. We can use this very fast and loose type to
use Agda to help us compute a definition for our morphisms:

#+begin_src Agda
ηₚ : ∀ {X : Set} → ∀{P Q : Poly} → ⟦ P ⟧ X → ⟦ Q ⟧ X
ηₚ ⟦P⟧ = {!!}
#+end_src

#+begin_src agda
Goal: ⟦ Q ⟧ X
————————————————————————————————————————————————————————————
F : ⟦ P ⟧ X
#+end_src

First of all, we know that our ~Functors~ are always encoded as Sigma
Types. This means we can pattern match on the initial ~Functor~ and
refine our hole with a tuple:

#+begin_src agda
ηₚ : ∀ {X : Set} → ∀{P Q : Poly} → ⟦ P ⟧ X → ⟦ Q ⟧ X
ηₚ (pbase , pfiber) = {!!} , {!!}
#+end_src

This also means that our morphism is going to be a product of two
functions, one for the first projection of the Sigma and one for the
second:

#+begin_src agda
infixr 0 _⇒_
record _⇒_ (P Q : Poly) : Set where
  constructor poly-map
  field
    map-base : ???
    map-fiber : ???
#+end_src

First Hole:
#+begin_src agda
Goal: Q .Base
————————————————————————————————————————————————————————————
pfiber : P .Fiber pbase → X
pbase  : P .Base
#+end_src

For our first hole we need to produce ~Q.Base~ which allows us to
refine our definition ~map-base~ to ~??? → Q .Base~.

In scope we have the two projections of the initial ~Functor~. So
~map-base~ must receive on or both of these. However we know that ~Q
.Base~ is not dependent but ~P .Fiber~ is dependent. This means we
cannot rely on ~P .Fiber~ to produce our ~Q .Base~.

This leaves us with ~pbase : P .Base~ which is not
dependent. Therefore ~map-base~ /must/ be ~P .Base → Q .Base~.

Second Hole:
#+begin_src agda
Goal: Q .Fiber ?1 → X
————————————————————————————————————————————————————————————
pfiber : P .Fiber pbase → X
pbase  : P .Base
#+end_src

This second hole is a lot more tricky. Recall that we are dealing
with ~Poly~ objects interpretered via ~⟦_⟧~. ~⟦_⟧~ produces a Sigma
whose second projection goes from the fiber at the indexing base to
~X~. The second projection of the ~Poly~ object itself doesn't
actually produce an ~X~.

Since our hole is a function we can refine it further with a lambda:

#+begin_src agda
ηₚ : ∀ {X : Set} → ∀{P Q : Poly} → ⟦ P ⟧ X → ⟦ Q ⟧ X
ηₚ (pbase , pfiber) = {!!} , (λ qfiber → {!!})
#+end_src

#+begin_src agda
Goal: X
————————————————————————————————————————————————————————————
qfiber : Q .Fiber ?0
pfiber : P .Fiber pbase → X
pbase  : P .Base
#+end_src

Now we have received a ~Q.Fiber~ and as we are dealing with the
~Functor~ interpretation of ~Q~ we must be able to produce an ~X~.

The only way to do that is via ~pfiber : P .Fiber pbase → X~, which
unintuitively means that ~map-fiber~ must produce a ~P .Fiber
pbase~. Since the fiber is depndent our map must also consume the ~P
.Fiber~.

The end result of all this confusion is a final type signature of ~(base : P
.Base) → Q .Fiber (map-base base) → P .Fiber base~.

Putting it all together we have:

#+begin_src agda
infixr 0 _⇒_
record _⇒_ (P Q : Poly) : Set where
  constructor poly-map
  field
    map-base : P .Base → Q .Base 
    map-fiber : (base : P .Base ) → Q .Fiber (map-tag base) → P .Fiber base
#+end_src

~map-base~ is easy to follow, but ~map-fiber~ is.. backwards. This
backwards forwards tension of morphisms in ~Poly~ is central to the
ability to represent dependent lenses and everything built ontop of
them.

* Poly Maps are Lenses

Morphisms in ~Poly~ are Dependent Lenses. First off an expository
definition of lenses:

#+begin_src haskell
  data Lens s t a b = Lens { get :: s -> a, set :: s -> b -> t }
#+end_src

This looks oddly similar to our ~Poly~ morphisms.

If we define a little helper function for describing monomials:

#+begin_src agda
-- | S × Yᵀ
monomial : Set → Set → Poly
(monomial S T) .Tag = S
(monomial S T) .Args  = λ _ → T
#+end_src

Because a monomial is constant on the exponent (~T~) we say that it is
non-dependent. Morphisms between these monomials are then
non-dependent lenses:

#+begin_src agda
Lens : Set → Set → Set → Set → Set
Lens S T A B = monomial S T ⇒ monomial A B

lens : ∀{S T A B : Set} → (S → A) → (S → B → T) → Lens S T A B
(lens get set) .map-base = get
(lens get set) .map-fiber = set

view : ∀{S T A B : Set} → Lens S T A B → S → A
view lens s = lens .map-base s

set : ∀{S T A B : Set} → Lens S T A B → B → S → T
set lens b s = lens .map-fiber s b
#+end_src

~get~ and ~set~ are literally ~map-base~ and ~map-fiber~!

Since lenses are merely morphisms on ~Poly~ we can demonstrate that
they compose correctly:

#+begin_src agda
projₗ : ∀{A B : Set} → Lens (A × B) (A × B) A A
projₗ = lens proj₁ λ where
  (fst , snd) → λ a → (a , snd)

projᵣ : ∀{A B : Set} → Lens (A × B) (A × B) B B
projᵣ = lens proj₂ λ where
  (fst , snd) → λ b → (fst , b)

example : Bool
example = view (projₗ ⨟ₚ projᵣ) ((true , false) , false)
#+end_src

Now what about the Dependent part? For this--along with monoidal
products, Moore Machines, and Wiring Diagrams--you will have to wait
for my followup post.
